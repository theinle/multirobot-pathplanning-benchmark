
description: |
  RRT*

#Goal 
goal_radius: 0.1                            # Distance threshold within a node is considered to have reached the goal 
p_goal: 0.93                                # Probability of performing goal sampling
general_goal_sampling: false                # True: For all tasks in mode goal sampling is done otherwise only for active task
step_size: 0.25                             # Max allowable distance that newly generated node can be from the nearest node in the tree 
cost_function: 2                            # 1: Sum(Euclidean norm per agent), 2: Worst(Euclidean norm per agent per edge)                       
ptc_threshold: 0.1                          # Converge Threshold
ptc_max_iter: 3000                          # Max iteration with no change before stopping
mode_probability: 1                         # Probability to choose new mode (0: unfiormly, 1: greedy None: equally, else: manually set) 
informed_sampling: false                    # True: Informed sampling is applied 
informed_sampling_version: 2                # If 'informed_sampling: true', the specified version is applied (0: Only regarding agent, 1: Including other agents 2: corrected 1)
cprofiler: False                            # Use cprofiler to run the 
show_path: False                            # Show the path in the end
cost: euclidean                             # Type of cost function: euclidean (Max euclidean norm), euclidean_tot

















description: |
  TODO
# step-size adjustable based on dimension??
# adapt goal radius for more DOF -> make it dependent on DOF
# TODO's in planner.py and env.py
# Handle singularities properly!
